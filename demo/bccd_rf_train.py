#!/usr/bin/env python3
# Copyright (c) Meta Platforms, Inc. and affiliates.
#
# This software may be used and distributed in accordance with
# the terms of the DINOv3 License Agreement.

"""
è¡€ç»†èƒåˆ†ç±»è®­ç»ƒè„šæœ¬ - ä½¿ç”¨DINOv3ç‰¹å¾ + éšæœºæ£®æ—åˆ†ç±»å™¨
è¿™ç§æ–¹æ³•æ›´ç®€å•ç›´æ¥ï¼Œé€šå¸¸åœ¨å°æ•°æ®é›†ä¸Šæ•ˆæœæ›´å¥½
"""

import argparse
import os
import sys
import xml.etree.ElementTree as ET
from pathlib import Path
from typing import Dict, List, Tuple, Optional
import pickle
import time

import torch
import numpy as np
from PIL import Image
from torchvision import transforms as T
from tqdm import tqdm
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix
import joblib

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), ".."))

# å…¨å±€é…ç½®
CLASS_NAMES = ['Platelets', 'RBC', 'WBC']
CLASS_TO_IDX = {name: idx for idx, name in enumerate(CLASS_NAMES)}


# ============================================================================
# 1. æ•°æ®å¤„ç†ç›¸å…³å‡½æ•°
# ============================================================================

def parse_xml_annotation(xml_file: Path) -> List[Dict]:
    """è§£æPASCAL VOCæ ¼å¼çš„XMLæ ‡æ³¨æ–‡ä»¶
    
    Args:
        xml_file: XMLæ–‡ä»¶è·¯å¾„
        
    Returns:
        æ ‡æ³¨å¯¹è±¡åˆ—è¡¨ï¼Œæ¯ä¸ªå¯¹è±¡åŒ…å«class_nameå’Œbbox
    """
    tree = ET.parse(xml_file)
    root = tree.getroot()
    
    objects = []
    for obj in root.findall('object'):
        class_name = obj.find('name').text
        bbox = obj.find('bndbox')
        xmin = int(bbox.find('xmin').text)
        ymin = int(bbox.find('ymin').text)
        xmax = int(bbox.find('xmax').text)
        ymax = int(bbox.find('ymax').text)
        
        objects.append({
            'class_name': class_name,
            'bbox': (xmin, ymin, xmax, ymax)
        })
    
    return objects


def validate_data_paths(data_root: Path) -> Tuple[Path, Path, Path, Path]:
    """éªŒè¯æ•°æ®è·¯å¾„æ˜¯å¦å­˜åœ¨å¹¶è¿”å›æ ‡å‡†åŒ–è·¯å¾„
    
    Args:
        data_root: æ•°æ®é›†æ ¹ç›®å½•
        
    Returns:
        (train_img_dir, train_ann_dir, test_img_dir, test_ann_dir)
    """
    train_img_dir = data_root / 'BCCD' / 'JPEGImages'
    train_ann_dir = data_root / 'BCCD' / 'Annotations'
    test_img_dir = data_root / 'BCCD_Dataset' / 'BCCD' / 'JPEGImages'
    test_ann_dir = data_root / 'BCCD_Dataset' / 'BCCD' / 'Annotations'
    
    # å¦‚æœæµ‹è¯•é›†è·¯å¾„ä¸å­˜åœ¨ï¼Œä½¿ç”¨è®­ç»ƒé›†è·¯å¾„
    if not test_img_dir.exists():
        test_img_dir = train_img_dir
        test_ann_dir = train_ann_dir
        print("æ³¨æ„: ä½¿ç”¨è®­ç»ƒé›†ä½œä¸ºéªŒè¯é›†")
    
    # éªŒè¯è®­ç»ƒé›†è·¯å¾„
    if not train_img_dir.exists():
        raise FileNotFoundError(f"è®­ç»ƒå›¾ç‰‡ç›®å½•ä¸å­˜åœ¨: {train_img_dir}")
    if not train_ann_dir.exists():
        raise FileNotFoundError(f"è®­ç»ƒæ ‡æ³¨ç›®å½•ä¸å­˜åœ¨: {train_ann_dir}")
    
    return train_img_dir, train_ann_dir, test_img_dir, test_ann_dir


def balance_dataset(X: np.ndarray, y: np.ndarray, 
                   method: str = 'undersample', 
                   random_state: int = 42) -> Tuple[np.ndarray, np.ndarray]:
    """å¹³è¡¡æ•°æ®é›†
    
    Args:
        X: ç‰¹å¾çŸ©é˜µ
        y: æ ‡ç­¾æ•°ç»„
        method: å¹³è¡¡æ–¹æ³• ('undersample' æˆ– 'oversample')
        random_state: éšæœºç§å­
        
    Returns:
        å¹³è¡¡åçš„(ç‰¹å¾, æ ‡ç­¾)
    """
    # è¾“å…¥éªŒè¯
    if len(X) == 0 or len(y) == 0:
        raise ValueError(f"âŒ è¾“å…¥æ•°æ®ä¸ºç©ºï¼X shape: {X.shape}, y shape: {y.shape}")
    
    if len(X) != len(y):
        raise ValueError(f"âŒ X å’Œ y çš„é•¿åº¦ä¸åŒ¹é…ï¼X: {len(X)}, y: {len(y)}")
    
    np.random.seed(random_state)
    
    # ç»Ÿè®¡ç±»åˆ«åˆ†å¸ƒ
    unique, counts = np.unique(y, return_counts=True)
    
    if len(unique) == 0:
        raise ValueError(f"âŒ æ²¡æœ‰æ‰¾åˆ°ä»»ä½•ç±»åˆ«ï¼è¯·æ£€æŸ¥æ ‡ç­¾æ•°æ®")
    
    class_counts = dict(zip(unique, counts))
    
    print(f"\nâš–ï¸  å¹³è¡¡æ•°æ®é›† (æ–¹æ³•: {method})")
    print(f"  åŸå§‹åˆ†å¸ƒ: {class_counts}")
    
    # æ‰§è¡Œå¹³è¡¡æ“ä½œ
    if method == 'undersample':
        X_balanced, y_balanced = _undersample(X, y, unique, counts)
    elif method == 'oversample':
        X_balanced, y_balanced = _oversample(X, y, unique, counts)
    else:
        raise ValueError(f"æœªçŸ¥çš„å¹³è¡¡æ–¹æ³•: {method}")
    
    # æ‰“ä¹±æ•°æ®
    shuffle_indices = np.random.permutation(len(X_balanced))
    X_balanced = X_balanced[shuffle_indices]
    y_balanced = y_balanced[shuffle_indices]
    
    balanced_counts = dict(zip(*np.unique(y_balanced, return_counts=True)))
    print(f"  å¹³è¡¡ååˆ†å¸ƒ: {balanced_counts}")
    print(f"  æ€»æ ·æœ¬: {len(X_balanced)} (åŸå§‹: {len(X)})")
    
    return X_balanced, y_balanced


def _undersample(X: np.ndarray, y: np.ndarray, 
                unique: np.ndarray, counts: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
    """ä¸‹é‡‡æ ·åˆ°æœ€å°ç±»åˆ«çš„æ•°é‡"""
    min_samples = min(counts)
    
    balanced_X = []
    balanced_y = []
    
    for class_idx in unique:
        class_mask = (y == class_idx)
        class_X = X[class_mask]
        class_y = y[class_mask]
        
        # éšæœºé‡‡æ ·
        indices = np.random.choice(len(class_X), min_samples, replace=False)
        balanced_X.append(class_X[indices])
        balanced_y.append(class_y[indices])
    
    return np.vstack(balanced_X), np.hstack(balanced_y)


def _oversample(X: np.ndarray, y: np.ndarray,
               unique: np.ndarray, counts: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
    """ä¸Šé‡‡æ ·åˆ°æœ€å¤§ç±»åˆ«çš„æ•°é‡"""
    max_samples = max(counts)
    
    balanced_X = []
    balanced_y = []
    
    for class_idx in unique:
        class_mask = (y == class_idx)
        class_X = X[class_mask]
        class_y = y[class_mask]
        
        # éšæœºé‡‡æ ·ï¼ˆå…è®¸é‡å¤ï¼‰
        indices = np.random.choice(len(class_X), max_samples, replace=True)
        balanced_X.append(class_X[indices])
        balanced_y.append(class_y[indices])
    
    return np.vstack(balanced_X), np.hstack(balanced_y)


# ============================================================================
# 2. æ¨¡å‹ç›¸å…³å‡½æ•°
# ============================================================================

def load_dinov3_model(model_name: str = 'dinov3_vits16', 
                      weights_path: Optional[str] = None, 
                      device: str = 'cuda', 
                      local_repo: Optional[str] = None) -> torch.nn.Module:
    """åŠ è½½DINOv3æ¨¡å‹ç”¨äºç‰¹å¾æå–
    
    Args:
        model_name: æ¨¡å‹åç§°
        weights_path: é¢„è®­ç»ƒæƒé‡è·¯å¾„
        device: è®¡ç®—è®¾å¤‡
        local_repo: æœ¬åœ°ä»“åº“è·¯å¾„ï¼Œå¦‚æœæä¾›åˆ™ä»æœ¬åœ°åŠ è½½
        
    Returns:
        DINOv3æ¨¡å‹å®ä¾‹
    """
    print(f"ğŸ“¦ åŠ è½½DINOv3æ¨¡å‹: {model_name}")
    
    # åŠ è½½æ¨¡å‹ç»“æ„
    model = _load_model_structure(model_name, local_repo)
    
    # åŠ è½½é¢„è®­ç»ƒæƒé‡
    if weights_path and os.path.exists(weights_path):
        _load_pretrained_weights(model, weights_path)
    
    model = model.to(device)
    model.eval()
    print("âœ“ DINOv3æ¨¡å‹åŠ è½½å®Œæˆ")
    
    return model


def _load_model_structure(model_name: str, local_repo: Optional[str]) -> torch.nn.Module:
    """åŠ è½½æ¨¡å‹ç»“æ„"""
    if local_repo and os.path.exists(local_repo):
        print(f"ğŸ“‚ ä½¿ç”¨æœ¬åœ°ä»“åº“: {local_repo}")
        model = torch.hub.load(
            repo_or_dir=local_repo,
            model=model_name,
            source='local',
            pretrained=False  # ç¨åæ‰‹åŠ¨åŠ è½½æƒé‡
        )
    else:
        model = torch.hub.load(
            repo_or_dir='facebookresearch/dinov3',
            model=model_name,
            source='github',
            pretrained=True  # ä½¿ç”¨é¢„è®­ç»ƒæƒé‡
        )
    
    return model


def _load_pretrained_weights(model: torch.nn.Module, weights_path: str):
    """åŠ è½½é¢„è®­ç»ƒæƒé‡åˆ°æ¨¡å‹"""
    print(f"ğŸ“¦ åŠ è½½é¢„è®­ç»ƒæƒé‡: {weights_path}")
    state_dict = torch.load(weights_path, map_location='cpu', weights_only=False)
    
    # å¤„ç†ä¸åŒçš„æƒé‡æ ¼å¼
    if 'teacher' in state_dict:
        state_dict = state_dict['teacher']
    elif 'model' in state_dict:
        state_dict = state_dict['model']
    
    # è¿‡æ»¤å¹¶åŠ è½½æƒé‡
    model_keys = set(model.state_dict().keys())
    filtered_dict = {}
    for k, v in state_dict.items():
        new_k = k.replace('backbone.', '').replace('module.', '')
        if new_k in model_keys:
            filtered_dict[new_k] = v
    
    model.load_state_dict(filtered_dict, strict=False)


# ============================================================================
# 3. ç‰¹å¾æå–ç›¸å…³å‡½æ•°
# ============================================================================

def extract_patch_features(model: torch.nn.Module, 
                          image: Image.Image, 
                          bbox: Tuple[int, int, int, int], 
                          patch_size: int = 224, 
                          device: str = 'cuda') -> np.ndarray:
    """ä»å›¾åƒçš„å•ä¸ªbboxåŒºåŸŸæå–DINOv3ç‰¹å¾
    
    Args:
        model: DINOv3æ¨¡å‹
        image: PILå›¾åƒ
        bbox: è¾¹ç•Œæ¡† (xmin, ymin, xmax, ymax)
        patch_size: è¾“å…¥patchå¤§å°
        device: è®¡ç®—è®¾å¤‡
        
    Returns:
        ç‰¹å¾å‘é‡ï¼ˆ1D numpy arrayï¼‰
    """
    # è£å‰ªå¹¶é¢„å¤„ç†å›¾åƒpatch
    patch_tensor = _preprocess_image_patch(image, bbox, patch_size, device)
    
    # æå–ç‰¹å¾
    with torch.no_grad():
        features = model.forward_features(patch_tensor)
        feat = _extract_cls_token(features)
        feat = feat.cpu().numpy().flatten()
    
    return feat


def _preprocess_image_patch(image: Image.Image, 
                            bbox: Tuple[int, int, int, int],
                            patch_size: int, 
                            device: str) -> torch.Tensor:
    """é¢„å¤„ç†å›¾åƒpatch"""
    xmin, ymin, xmax, ymax = bbox
    
    # è£å‰ªbboxåŒºåŸŸ
    patch = image.crop((xmin, ymin, xmax, ymax))
    
    # è½¬æ¢ä¸ºtensor
    transform = T.Compose([
        T.Resize((patch_size, patch_size)),
        T.ToTensor(),
        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])
    
    patch_tensor = transform(patch).unsqueeze(0).to(device)
    return patch_tensor


def _extract_cls_token(features) -> torch.Tensor:
    """ä»DINOv3ç‰¹å¾ä¸­æå–CLS token"""
    # ä¼˜å…ˆä½¿ç”¨x_norm_clstoken
    if hasattr(features, 'x_norm_clstoken'):
        return features.x_norm_clstoken
    
    # å°è¯•ä½¿ç”¨tokensçš„ç¬¬ä¸€ä¸ª
    if hasattr(features, 'tokens'):
        return features.tokens[:, 0]
    
    # å¤„ç†å­—å…¸æ ¼å¼çš„è¾“å‡º
    if isinstance(features, dict):
        if 'x_norm_clstoken' in features:
            return features['x_norm_clstoken']
        
        # ä½¿ç”¨patch tokensçš„å¹³å‡å€¼
        feat = features.get('x_norm_patchtokens', features.get('tokens', None))
        if feat is not None and feat.dim() > 2:
            return feat.mean(dim=1)
    
    # å¤„ç†tensorè¾“å‡º
    if features.dim() == 3:
        return features[:, 0]
    
    return features


def extract_dataset_features(model: torch.nn.Module, 
                            image_dir: Path, 
                            annotation_dir: Path, 
                            split: str = 'train', 
                            device: str = 'cuda', 
                            max_samples: Optional[int] = None) -> Tuple[np.ndarray, np.ndarray]:
    """ä»æ•°æ®é›†ä¸­æå–æ‰€æœ‰bboxçš„ç‰¹å¾
    
    Args:
        model: DINOv3æ¨¡å‹
        image_dir: å›¾åƒç›®å½•
        annotation_dir: æ ‡æ³¨ç›®å½•
        split: æ•°æ®é›†åˆ’åˆ†åç§°ï¼ˆç”¨äºæ˜¾ç¤ºï¼‰
        device: è®¡ç®—è®¾å¤‡
        max_samples: æœ€å¤§æ ·æœ¬æ•°ï¼ˆç”¨äºå¿«é€Ÿæµ‹è¯•ï¼‰
        
    Returns:
        (features, labels) - ç‰¹å¾çŸ©é˜µå’Œæ ‡ç­¾æ•°ç»„
    """
    print(f"\nğŸ“Š æå–{split}é›†ç‰¹å¾...")
    
    # è·å–å›¾åƒæ–‡ä»¶åˆ—è¡¨
    image_files = sorted(list(image_dir.glob('*.jpg')))
    if max_samples:
        image_files = image_files[:max_samples]
    
    features_list = []
    labels_list = []
    
    # éå†æ‰€æœ‰å›¾åƒ
    for img_file in tqdm(image_files, desc=f"å¤„ç†{split}é›†"):
        # æå–è¯¥å›¾åƒçš„æ‰€æœ‰å¯¹è±¡ç‰¹å¾
        img_features, img_labels = _extract_image_features(
            model, img_file, annotation_dir, device
        )
        features_list.extend(img_features)
        labels_list.extend(img_labels)
    
    # è½¬æ¢ä¸ºnumpyæ•°ç»„
    features = np.array(features_list)
    labels = np.array(labels_list)
    
    # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
    _print_extraction_summary(features, labels, split)
    
    return features, labels


def _extract_image_features(model: torch.nn.Module, 
                            img_file: Path, 
                            annotation_dir: Path, 
                            device: str) -> Tuple[List[np.ndarray], List[int]]:
    """æå–å•å¼ å›¾åƒä¸­æ‰€æœ‰å¯¹è±¡çš„ç‰¹å¾"""
    # æŸ¥æ‰¾å¯¹åº”çš„XMLæ ‡æ³¨æ–‡ä»¶
    xml_file = annotation_dir / f"{img_file.stem}.xml"
    if not xml_file.exists():
        return [], []
    
    # è§£ææ ‡æ³¨
    annotations = parse_xml_annotation(xml_file)
    if not annotations:
        return [], []
    
    # åŠ è½½å›¾åƒ
    image = Image.open(img_file).convert('RGB')
    
    features_list = []
    labels_list = []
    
    # æå–æ¯ä¸ªbboxçš„ç‰¹å¾
    for obj in annotations:
        class_name = obj['class_name']
        if class_name not in CLASS_TO_IDX:
            continue
        
        bbox = obj['bbox']
        
        try:
            feat = extract_patch_features(model, image, bbox, device=device)
            features_list.append(feat)
            labels_list.append(CLASS_TO_IDX[class_name])
        except Exception as e:
            print(f"è­¦å‘Š: æå–ç‰¹å¾å¤±è´¥ {img_file.name} - {class_name}: {e}")
            continue
    
    return features_list, labels_list


def _print_extraction_summary(features: np.ndarray, labels: np.ndarray, split: str):
    """æ‰“å°ç‰¹å¾æå–çš„ç»Ÿè®¡ä¿¡æ¯"""
    print(f"âœ“ æå–å®Œæˆ: {len(features)} ä¸ªæ ·æœ¬")
    print(f"  ç‰¹å¾ç»´åº¦: {features.shape}")
    
    unique, counts = np.unique(labels, return_counts=True)
    class_dist = {CLASS_NAMES[idx]: count for idx, count in zip(unique, counts)}
    print(f"  ç±»åˆ«åˆ†å¸ƒ: {class_dist}")


# ============================================================================
# 4. è®­ç»ƒå’Œè¯„ä¼°ç›¸å…³å‡½æ•°
# ============================================================================

def train_random_forest(X_train: np.ndarray, 
                       y_train: np.ndarray,
                       n_estimators: int = 200, 
                       max_depth: int = 30,
                       random_state: int = 42) -> RandomForestClassifier:
    """è®­ç»ƒéšæœºæ£®æ—åˆ†ç±»å™¨
    
    Args:
        X_train: è®­ç»ƒç‰¹å¾
        y_train: è®­ç»ƒæ ‡ç­¾
        n_estimators: æ ‘çš„æ•°é‡
        max_depth: æœ€å¤§æ·±åº¦
        random_state: éšæœºç§å­
        
    Returns:
        è®­ç»ƒå¥½çš„éšæœºæ£®æ—åˆ†ç±»å™¨
    """
    print(f"\nğŸŒ² è®­ç»ƒéšæœºæ£®æ—åˆ†ç±»å™¨...")
    print(f"  å‚æ•°: n_estimators={n_estimators}, max_depth={max_depth}")
    
    start_time = time.time()
    
    # åˆ›å»ºå¹¶è®­ç»ƒéšæœºæ£®æ—
    clf = RandomForestClassifier(
        n_estimators=n_estimators,
        max_depth=max_depth,
        random_state=random_state,
        n_jobs=-1,  # ä½¿ç”¨æ‰€æœ‰CPUæ ¸å¿ƒ
        verbose=1,
        class_weight='balanced',  # å¤„ç†ç±»åˆ«ä¸å¹³è¡¡
        min_samples_split=5,
        min_samples_leaf=2
    )
    
    clf.fit(X_train, y_train)
    
    train_time = time.time() - start_time
    print(f"âœ“ è®­ç»ƒå®Œæˆ (ç”¨æ—¶: {train_time:.2f}ç§’)")
    
    # æ‰“å°ç‰¹å¾é‡è¦æ€§ç»Ÿè®¡
    _print_feature_importance(clf)
    
    return clf


def _print_feature_importance(clf: RandomForestClassifier):
    """æ‰“å°ç‰¹å¾é‡è¦æ€§ç»Ÿè®¡"""
    print("\nç‰¹å¾é‡è¦æ€§ç»Ÿè®¡:")
    print(f"  å¹³å‡é‡è¦æ€§: {clf.feature_importances_.mean():.6f}")
    print(f"  æœ€å¤§é‡è¦æ€§: {clf.feature_importances_.max():.6f}")
    print(f"  æœ€å°é‡è¦æ€§: {clf.feature_importances_.min():.6f}")


def evaluate_model(clf: RandomForestClassifier, 
                  X: np.ndarray, 
                  y: np.ndarray, 
                  split_name: str = "æ•°æ®é›†"):
    """è¯„ä¼°æ¨¡å‹æ€§èƒ½
    
    Args:
        clf: è®­ç»ƒå¥½çš„åˆ†ç±»å™¨
        X: ç‰¹å¾
        y: æ ‡ç­¾
        split_name: æ•°æ®é›†åç§°ï¼ˆç”¨äºæ˜¾ç¤ºï¼‰
    """
    print(f"\nğŸ“ˆ è¯„ä¼°{split_name}...")
    
    # è®¡ç®—å‡†ç¡®ç‡
    accuracy = clf.score(X, y)
    print(f"\n{split_name}å‡†ç¡®ç‡: {accuracy:.4f}")
    
    # é¢„æµ‹å¹¶ç”ŸæˆæŠ¥å‘Š
    y_pred = clf.predict(X)
    
    print(f"\n{split_name}åˆ†ç±»æŠ¥å‘Š:")
    print(classification_report(y, y_pred, target_names=CLASS_NAMES))
    
    print(f"\n{split_name}æ··æ·†çŸ©é˜µ:")
    print(confusion_matrix(y, y_pred))


# ============================================================================
# 5. ä¿å­˜å’ŒåŠ è½½ç›¸å…³å‡½æ•°
# ============================================================================

def save_features(output_dir: Path, 
                 X_train: np.ndarray, 
                 y_train: np.ndarray,
                 X_val: Optional[np.ndarray], 
                 y_val: Optional[np.ndarray],
                 balance_method: str):
    """ä¿å­˜æå–çš„ç‰¹å¾
    
    Args:
        output_dir: è¾“å‡ºç›®å½•
        X_train: è®­ç»ƒç‰¹å¾
        y_train: è®­ç»ƒæ ‡ç­¾
        X_val: éªŒè¯ç‰¹å¾
        y_val: éªŒè¯æ ‡ç­¾
        balance_method: æ•°æ®å¹³è¡¡æ–¹æ³•
    """
    features_path = output_dir / 'features.pkl'
    print(f"\nğŸ’¾ ä¿å­˜ç‰¹å¾åˆ°: {features_path}")
    
    with open(features_path, 'wb') as f:
        pickle.dump({
            'X_train': X_train,
            'y_train': y_train,
            'X_val': X_val,
            'y_val': y_val,
            'class_names': CLASS_NAMES,
            'class_to_idx': CLASS_TO_IDX,
            'balance_method': balance_method
        }, f)


def save_model(clf: RandomForestClassifier, output_dir: Path):
    """ä¿å­˜éšæœºæ£®æ—æ¨¡å‹
    
    Args:
        clf: è®­ç»ƒå¥½çš„åˆ†ç±»å™¨
        output_dir: è¾“å‡ºç›®å½•
    """
    model_path = output_dir / 'rf_classifier.pkl'
    print(f"\nğŸ’¾ ä¿å­˜éšæœºæ£®æ—æ¨¡å‹åˆ°: {model_path}")
    joblib.dump(clf, model_path)


def save_config(output_dir: Path, args: argparse.Namespace):
    """ä¿å­˜è®­ç»ƒé…ç½®
    
    Args:
        output_dir: è¾“å‡ºç›®å½•
        args: å‘½ä»¤è¡Œå‚æ•°
    """
    config_path = output_dir / 'config.pkl'
    print(f"ğŸ’¾ ä¿å­˜é…ç½®åˆ°: {config_path}")
    
    config = {
        'dinov3_model': args.dinov3_model,
        'dinov3_weights': args.dinov3_weights,
        'patch_size': args.patch_size,
        'n_estimators': args.n_estimators,
        'max_depth': args.max_depth,
        'balance_method': args.balance_method,
        'class_names': CLASS_NAMES,
        'class_to_idx': CLASS_TO_IDX
    }
    
    with open(config_path, 'wb') as f:
        pickle.dump(config, f)


# ============================================================================
# 6. ä¸»ç¨‹åºç›¸å…³å‡½æ•°
# ============================================================================

def parse_arguments() -> argparse.Namespace:
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(description='è¡€ç»†èƒåˆ†ç±»è®­ç»ƒ - DINOv3 + éšæœºæ£®æ—')
    
    # æ•°æ®è·¯å¾„
    parser.add_argument('--data_root', type=str, default='../BCCD_Dataset',
                       help='BCCDæ•°æ®é›†æ ¹ç›®å½•')
    parser.add_argument('--output_dir', type=str, default='output/bccd_rf_model',
                       help='è¾“å‡ºç›®å½•')
    
    # æ¨¡å‹å‚æ•°
    parser.add_argument('--dinov3_model', type=str, default='dinov3_vits16',
                       choices=['dinov3_vits16', 'dinov3_vitb16', 'dinov3_vitl16', 'dinov3_vitg14',
                               'dinov3_vith16plus', 'dinov3_vit7b16', 'dinov3_vits16plus', 'dinov3_vitl16plus'],
                       help='DINOv3æ¨¡å‹ç±»å‹')
    parser.add_argument('--dinov3_weights', type=str, default=None,
                       help='DINOv3é¢„è®­ç»ƒæƒé‡è·¯å¾„')
    parser.add_argument('--patch_size', type=int, default=224,
                       help='è¾“å…¥patchå¤§å°')
    
    # éšæœºæ£®æ—å‚æ•°
    parser.add_argument('--n_estimators', type=int, default=200,
                       help='éšæœºæ£®æ—æ ‘çš„æ•°é‡')
    parser.add_argument('--max_depth', type=int, default=30,
                       help='éšæœºæ£®æ—æœ€å¤§æ·±åº¦')
    parser.add_argument('--balance_method', type=str, default='oversample',
                       choices=['undersample', 'oversample', 'none'],
                       help='æ•°æ®å¹³è¡¡æ–¹æ³•ï¼šundersample(ä¸‹é‡‡æ ·), oversample(ä¸Šé‡‡æ ·), none(ä¸å¹³è¡¡)')
    
    # è®­ç»ƒå‚æ•°
    parser.add_argument('--local_repo', type=str, default='/data/william/Workspace/dinov3',
                       help='æœ¬åœ°DINOv3ä»“åº“è·¯å¾„')
    parser.add_argument('--device', type=str, default='cuda',
                       help='è®¾å¤‡ (cuda æˆ– cpu)')
    parser.add_argument('--max_samples', type=int, default=None,
                       help='æœ€å¤§æ ·æœ¬æ•°ï¼ˆç”¨äºå¿«é€Ÿæµ‹è¯•ï¼‰')
    parser.add_argument('--random_seed', type=int, default=42,
                       help='éšæœºç§å­')
    
    return parser.parse_args()


def setup_environment(args: argparse.Namespace):
    """è®¾ç½®è¿è¡Œç¯å¢ƒ
    
    Args:
        args: å‘½ä»¤è¡Œå‚æ•°
    """
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = Path(args.output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # è®¾ç½®éšæœºç§å­
    np.random.seed(args.random_seed)
    torch.manual_seed(args.random_seed)
    
    # æ£€æŸ¥è®¾å¤‡
    if args.device == 'cuda' and not torch.cuda.is_available():
        print("è­¦å‘Š: CUDAä¸å¯ç”¨ï¼Œä½¿ç”¨CPU")
        args.device = 'cpu'


def print_header(args: argparse.Namespace):
    """æ‰“å°ç¨‹åºæ ‡é¢˜å’Œé…ç½®ä¿¡æ¯"""
    print("="*80)
    print("è¡€ç»†èƒåˆ†ç±»è®­ç»ƒ - DINOv3ç‰¹å¾ + éšæœºæ£®æ—åˆ†ç±»å™¨")
    print("="*80)
    print(f"æ•°æ®é›†: {args.data_root}")
    print(f"DINOv3æ¨¡å‹: {args.dinov3_model}")
    print(f"éšæœºæ£®æ—å‚æ•°: n_estimators={args.n_estimators}, max_depth={args.max_depth}")
    print(f"æ•°æ®å¹³è¡¡æ–¹æ³•: {args.balance_method}")
    print(f"è¾“å‡ºç›®å½•: {args.output_dir}")
    print(f"è®¾å¤‡: {args.device}")
    print("="*80)


def validate_extracted_data(X: Optional[np.ndarray], 
                           y: Optional[np.ndarray], 
                           data_type: str,
                           img_dir: Path, 
                           ann_dir: Path):
    """éªŒè¯æå–çš„æ•°æ®æ˜¯å¦æœ‰æ•ˆ
    
    Args:
        X: ç‰¹å¾çŸ©é˜µ
        y: æ ‡ç­¾æ•°ç»„
        data_type: æ•°æ®ç±»å‹åç§°
        img_dir: å›¾åƒç›®å½•
        ann_dir: æ ‡æ³¨ç›®å½•
        
    Raises:
        RuntimeError: å¦‚æœæ•°æ®æ— æ•ˆ
    """
    if X is None or y is None or len(X) == 0 or len(y) == 0:
        error_msg = f"\nâŒ é”™è¯¯ï¼šæ²¡æœ‰æå–åˆ°{data_type}æ•°æ®ï¼\n"
        error_msg += f"  è¯·æ£€æŸ¥ï¼š\n"
        error_msg += f"  1. {data_type}å›¾ç‰‡ç›®å½•æ˜¯å¦å­˜åœ¨ä¸”åŒ…å«å›¾ç‰‡: {img_dir}\n"
        error_msg += f"  2. æ ‡æ³¨ç›®å½•æ˜¯å¦å­˜åœ¨ä¸”åŒ…å«æ ‡æ³¨æ–‡ä»¶: {ann_dir}\n"
        error_msg += f"  3. å›¾ç‰‡å’Œæ ‡æ³¨æ–‡ä»¶çš„æ ¼å¼æ˜¯å¦æ­£ç¡®"
        raise RuntimeError(error_msg)
    
    print(f"\nâœ… æˆåŠŸæå–{data_type}ç‰¹å¾: {len(X)} ä¸ªæ ·æœ¬")


def main():
    """ä¸»å‡½æ•°ï¼šåè°ƒæ•´ä¸ªè®­ç»ƒæµç¨‹"""
    # 1. è§£æå‚æ•°å’Œè®¾ç½®ç¯å¢ƒ
    args = parse_arguments()
    setup_environment(args)
    print_header(args)
    
    # 2. éªŒè¯æ•°æ®è·¯å¾„
    data_root = Path(args.data_root)
    train_img_dir, train_ann_dir, test_img_dir, test_ann_dir = validate_data_paths(data_root)
    
    # 3. åŠ è½½DINOv3æ¨¡å‹
    dinov3_model = load_dinov3_model(
        model_name=args.dinov3_model,
        weights_path=args.dinov3_weights,
        device=args.device,
        local_repo=args.local_repo
    )
    
    # 4. æå–è®­ç»ƒé›†ç‰¹å¾
    X_train, y_train = extract_dataset_features(
        dinov3_model, 
        train_img_dir, 
        train_ann_dir,
        split='train',
        device=args.device,
        max_samples=args.max_samples
    )
    
    validate_extracted_data(X_train, y_train, 'è®­ç»ƒ', train_img_dir, train_ann_dir)
    
    # 5. æå–éªŒè¯é›†ç‰¹å¾ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    X_val, y_val = None, None
    if test_img_dir != train_img_dir:
        X_val, y_val = extract_dataset_features(
            dinov3_model,
            test_img_dir,
            test_ann_dir,
            split='test',
            device=args.device,
            max_samples=args.max_samples
        )
        if X_val is not None and len(X_val) > 0:
            print(f"âœ… æˆåŠŸæå–éªŒè¯ç‰¹å¾: {len(X_val)} ä¸ªæ ·æœ¬")
    
    # 6. å¹³è¡¡è®­ç»ƒæ•°æ®
    balance_method = None if args.balance_method == 'none' else args.balance_method
    if balance_method:
        print(f"\nâš–ï¸  åº”ç”¨æ•°æ®å¹³è¡¡æ–¹æ³•: {balance_method}")
        X_train, y_train = balance_dataset(
            X_train, y_train,
            method=balance_method,
            random_state=args.random_seed
        )
    
    # 7. ä¿å­˜ç‰¹å¾
    output_dir = Path(args.output_dir)
    save_features(output_dir, X_train, y_train, X_val, y_val, args.balance_method)
    
    # 8. è®­ç»ƒéšæœºæ£®æ—
    rf_classifier = train_random_forest(
        X_train, y_train,
        n_estimators=args.n_estimators,
        max_depth=args.max_depth,
        random_state=args.random_seed
    )
    
    # 9. è¯„ä¼°æ¨¡å‹
    evaluate_model(rf_classifier, X_train, y_train, split_name="è®­ç»ƒé›†")
    
    if X_val is not None and y_val is not None:
        evaluate_model(rf_classifier, X_val, y_val, split_name="éªŒè¯é›†")
    
    # 10. ä¿å­˜æ¨¡å‹å’Œé…ç½®
    save_model(rf_classifier, output_dir)
    save_config(output_dir, args)
    
    # 11. æ‰“å°å®Œæˆä¿¡æ¯
    print("\n" + "="*80)
    print("è®­ç»ƒå®Œæˆï¼")
    print(f"æ¨¡å‹ä¿å­˜åœ¨: {output_dir}")
    print("="*80)


if __name__ == '__main__':
    main()

#!/usr/bin/env python3
# Copyright (c) Meta Platforms, Inc. and affiliates.
#
# This software may be used and distributed in accordance with
# the terms of the DINOv3 License Agreement.

"""
è¡€ç»†èƒåˆ†ç±»æ¨ç†è„šæœ¬ - ä½¿ç”¨DINOv3ç‰¹å¾ + éšæœºæ£®æ—åˆ†ç±»å™¨
æ”¯æŒä¸¤ç§æ¨¡å¼:
1. å•å¼ å›¾åƒçš„å®Œæ•´æ£€æµ‹ï¼ˆä½¿ç”¨æ»‘åŠ¨çª—å£ï¼‰
2. å¯¹å·²æœ‰æ ‡æ³¨æ¡†è¿›è¡Œåˆ†ç±»
"""

import argparse
import os
import sys
from pathlib import Path
from typing import Dict, List, Tuple
import pickle
import xml.etree.ElementTree as ET

import torch
from torchvision import transforms as T
from PIL import Image, ImageDraw, ImageFont
import numpy as np
import joblib
from tqdm import tqdm

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), ".."))


# ç±»åˆ«é¢œè‰²
COLORS = {
    'Platelets': (255, 0, 0),      # çº¢è‰² - è¡€å°æ¿
    'RBC': (0, 255, 0),            # ç»¿è‰² - çº¢ç»†èƒ
    'WBC': (0, 0, 255),            # è“è‰² - ç™½ç»†èƒ
}


def load_dinov3_model(model_name: str = 'dinov3_vits16', weights_path: str = None, 
                      device='cuda', local_repo: str = None):
    """åŠ è½½DINOv3æ¨¡å‹ç”¨äºç‰¹å¾æå–
    
    Args:
        model_name: æ¨¡å‹åç§°
        weights_path: é¢„è®­ç»ƒæƒé‡è·¯å¾„
        device: è®¾å¤‡
        local_repo: æœ¬åœ°ä»“åº“è·¯å¾„ï¼Œå¦‚æœæä¾›åˆ™ä»æœ¬åœ°åŠ è½½
    """
    print(f"ğŸ“¦ åŠ è½½DINOv3æ¨¡å‹: {model_name}")
    
    # å¦‚æœæä¾›äº†æœ¬åœ°ä»“åº“è·¯å¾„ï¼Œä»æœ¬åœ°åŠ è½½
    if local_repo and os.path.exists(local_repo):
        print(f"ğŸ“‚ ä½¿ç”¨æœ¬åœ°ä»“åº“: {local_repo}")
        model = torch.hub.load(
            repo_or_dir=local_repo,
            model=model_name,
            source='local',
            pretrained=False  # ç¨åæ‰‹åŠ¨åŠ è½½æƒé‡
        )
    else:
        # ä»GitHubåŠ è½½
        model = torch.hub.load(
            repo_or_dir='facebookresearch/dinov3',
            model=model_name,
            source='github',
            pretrained=True  # ä½¿ç”¨é¢„è®­ç»ƒæƒé‡ï¼
        )
    
    # åŠ è½½é¢„è®­ç»ƒæƒé‡
    if weights_path and os.path.exists(weights_path):
        print(f"ğŸ“¦ åŠ è½½é¢„è®­ç»ƒæƒé‡: {weights_path}")
        state_dict = torch.load(weights_path, map_location='cpu', weights_only=False)
        
        if 'teacher' in state_dict:
            state_dict = state_dict['teacher']
        elif 'model' in state_dict:
            state_dict = state_dict['model']
        
        model_keys = set(model.state_dict().keys())
        filtered_dict = {}
        for k, v in state_dict.items():
            new_k = k.replace('backbone.', '').replace('module.', '')
            if new_k in model_keys:
                filtered_dict[new_k] = v
        
        model.load_state_dict(filtered_dict, strict=False)
    
    model = model.to(device)
    model.eval()
    print("âœ“ DINOv3æ¨¡å‹åŠ è½½å®Œæˆ")
    
    return model


def extract_patch_features(model, image: Image.Image, bbox: Tuple[int, int, int, int], 
                          patch_size: int = 224, device='cuda') -> np.ndarray:
    """ä»å›¾åƒä¸­æå–å•ä¸ªbboxçš„ç‰¹å¾"""
    xmin, ymin, xmax, ymax = bbox
    
    # ç¡®ä¿bboxåœ¨å›¾åƒèŒƒå›´å†…
    img_width, img_height = image.size
    xmin = max(0, min(xmin, img_width))
    ymin = max(0, min(ymin, img_height))
    xmax = max(0, min(xmax, img_width))
    ymax = max(0, min(ymax, img_height))
    
    if xmax <= xmin or ymax <= ymin:
        return None
    
    # è£å‰ªå¹¶resize bboxåŒºåŸŸ
    patch = image.crop((xmin, ymin, xmax, ymax))
    
    # è½¬æ¢ä¸ºtensor
    transform = T.Compose([
        T.Resize((patch_size, patch_size)),
        T.ToTensor(),
        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])
    
    patch_tensor = transform(patch).unsqueeze(0).to(device)
    
    # æå–ç‰¹å¾
    with torch.no_grad():
        features = model.forward_features(patch_tensor)
        
        # ä½¿ç”¨CLS tokençš„ç‰¹å¾
        if hasattr(features, 'x_norm_clstoken'):
            feat = features.x_norm_clstoken
        elif hasattr(features, 'tokens'):
            feat = features.tokens[:, 0]  # CLS token
        else:
            if isinstance(features, dict):
                if 'x_norm_clstoken' in features:
                    feat = features['x_norm_clstoken']
                else:
                    feat = features.get('x_norm_patchtokens', features.get('tokens', None))
                    if feat is not None and feat.dim() > 2:
                        feat = feat.mean(dim=1)
            else:
                if features.dim() == 3:
                    feat = features[:, 0]
                else:
                    feat = features
        
        feat = feat.cpu().numpy().flatten()
    
    return feat


def parse_xml_annotation(xml_file: Path) -> List[Dict]:
    """è§£æPASCAL VOCæ ¼å¼çš„XMLæ ‡æ³¨æ–‡ä»¶"""
    tree = ET.parse(xml_file)
    root = tree.getroot()
    
    objects = []
    for obj in root.findall('object'):
        class_name = obj.find('name').text
        bbox = obj.find('bndbox')
        xmin = int(bbox.find('xmin').text)
        ymin = int(bbox.find('ymin').text)
        xmax = int(bbox.find('xmax').text)
        ymax = int(bbox.find('ymax').text)
        
        objects.append({
            'class_name': class_name,
            'bbox': (xmin, ymin, xmax, ymax)
        })
    
    return objects


def generate_sliding_windows(image_size: Tuple[int, int], window_size: int = 64, 
                             stride: int = 32, min_size: int = 20) -> List[Tuple[int, int, int, int]]:
    """ç”Ÿæˆæ»‘åŠ¨çª—å£çš„è¾¹ç•Œæ¡†
    
    Args:
        image_size: å›¾åƒå°ºå¯¸ (width, height)
        window_size: çª—å£å¤§å°
        stride: æ»‘åŠ¨æ­¥é•¿
        min_size: æœ€å°çª—å£å¤§å°
        
    Returns:
        è¾¹ç•Œæ¡†åˆ—è¡¨ (xmin, ymin, xmax, ymax)
    """
    width, height = image_size
    windows = []
    
    # å¤šå°ºåº¦æ»‘åŠ¨çª—å£
    scales = [32, 48, 64, 96, 128]
    
    for scale in scales:
        if scale < min_size:
            continue
        
        # è®¡ç®—æ­¥é•¿ï¼ˆçª—å£å¤§å°çš„ä¸€åŠï¼‰
        step = max(scale // 2, 16)
        
        for y in range(0, height - scale + 1, step):
            for x in range(0, width - scale + 1, step):
                windows.append((x, y, x + scale, y + scale))
    
    return windows


def non_max_suppression(boxes: List[Tuple], scores: List[float], 
                       iou_threshold: float = 0.5) -> List[int]:
    """éæå¤§å€¼æŠ‘åˆ¶
    
    Args:
        boxes: è¾¹ç•Œæ¡†åˆ—è¡¨
        scores: ç½®ä¿¡åº¦åˆ†æ•°åˆ—è¡¨
        iou_threshold: IoUé˜ˆå€¼
        
    Returns:
        ä¿ç•™çš„è¾¹ç•Œæ¡†ç´¢å¼•
    """
    if len(boxes) == 0:
        return []
    
    boxes = np.array(boxes)
    scores = np.array(scores)
    
    x1 = boxes[:, 0]
    y1 = boxes[:, 1]
    x2 = boxes[:, 2]
    y2 = boxes[:, 3]
    
    areas = (x2 - x1) * (y2 - y1)
    order = scores.argsort()[::-1]
    
    keep = []
    while order.size > 0:
        i = order[0]
        keep.append(i)
        
        xx1 = np.maximum(x1[i], x1[order[1:]])
        yy1 = np.maximum(y1[i], y1[order[1:]])
        xx2 = np.minimum(x2[i], x2[order[1:]])
        yy2 = np.minimum(y2[i], y2[order[1:]])
        
        w = np.maximum(0.0, xx2 - xx1)
        h = np.maximum(0.0, yy2 - yy1)
        inter = w * h
        
        iou = inter / (areas[i] + areas[order[1:]] - inter)
        
        inds = np.where(iou <= iou_threshold)[0]
        order = order[inds + 1]
    
    return keep


def classify_with_annotations(image_path: Path, xml_path: Path, model, rf_classifier, 
                              config: Dict, device='cuda') -> Tuple[Image.Image, List[Dict]]:
    """ä½¿ç”¨å·²æœ‰æ ‡æ³¨æ¡†è¿›è¡Œåˆ†ç±»
    
    Args:
        image_path: å›¾åƒè·¯å¾„
        xml_path: XMLæ ‡æ³¨æ–‡ä»¶è·¯å¾„
        model: DINOv3æ¨¡å‹
        rf_classifier: éšæœºæ£®æ—åˆ†ç±»å™¨
        config: é…ç½®å­—å…¸
        device: è®¾å¤‡
        
    Returns:
        (å¯è§†åŒ–å›¾åƒ, æ£€æµ‹ç»“æœåˆ—è¡¨)
    """
    # åŠ è½½å›¾åƒ
    image = Image.open(image_path).convert('RGB')
    
    # è§£ææ ‡æ³¨
    annotations = parse_xml_annotation(xml_path)
    
    # æå–ç‰¹å¾å¹¶åˆ†ç±»
    results = []
    for obj in tqdm(annotations, desc="åˆ†ç±»æ ‡æ³¨æ¡†"):
        bbox = obj['bbox']
        
        # æå–ç‰¹å¾
        feat = extract_patch_features(model, image, bbox, 
                                     patch_size=config['patch_size'], 
                                     device=device)
        if feat is None:
            continue
        
        # é¢„æµ‹ç±»åˆ«
        pred_label = rf_classifier.predict([feat])[0]
        pred_proba = rf_classifier.predict_proba([feat])[0]
        confidence = pred_proba[pred_label]
        
        pred_class = config['class_names'][pred_label]
        true_class = obj['class_name']
        
        results.append({
            'bbox': bbox,
            'predicted_class': pred_class,
            'true_class': true_class,
            'confidence': confidence,
            'correct': pred_class == true_class
        })
    
    # å¯è§†åŒ–
    vis_image = visualize_detections(image, results, show_true_labels=True)
    
    return vis_image, results


def detect_sliding_window(image_path: Path, model, rf_classifier, config: Dict,
                         device='cuda', conf_threshold: float = 0.7,
                         nms_threshold: float = 0.3) -> Tuple[Image.Image, List[Dict]]:
    """ä½¿ç”¨æ»‘åŠ¨çª—å£è¿›è¡Œæ£€æµ‹
    
    Args:
        image_path: å›¾åƒè·¯å¾„
        model: DINOv3æ¨¡å‹
        rf_classifier: éšæœºæ£®æ—åˆ†ç±»å™¨
        config: é…ç½®å­—å…¸
        device: è®¾å¤‡
        conf_threshold: ç½®ä¿¡åº¦é˜ˆå€¼
        nms_threshold: NMSçš„IoUé˜ˆå€¼
        
    Returns:
        (å¯è§†åŒ–å›¾åƒ, æ£€æµ‹ç»“æœåˆ—è¡¨)
    """
    # åŠ è½½å›¾åƒ
    image = Image.open(image_path).convert('RGB')
    img_width, img_height = image.size
    
    print(f"å›¾åƒå°ºå¯¸: {img_width} x {img_height}")
    
    # ç”Ÿæˆæ»‘åŠ¨çª—å£
    windows = generate_sliding_windows((img_width, img_height))
    print(f"ç”Ÿæˆ {len(windows)} ä¸ªå€™é€‰çª—å£")
    
    # å¯¹æ¯ä¸ªçª—å£è¿›è¡Œåˆ†ç±»
    detections = []
    for bbox in tqdm(windows, desc="å¤„ç†çª—å£"):
        # æå–ç‰¹å¾
        feat = extract_patch_features(model, image, bbox,
                                     patch_size=config['patch_size'],
                                     device=device)
        if feat is None:
            continue
        
        # é¢„æµ‹
        pred_proba = rf_classifier.predict_proba([feat])[0]
        pred_label = pred_proba.argmax()
        confidence = pred_proba[pred_label]
        
        # è¿‡æ»¤ä½ç½®ä¿¡åº¦
        if confidence > conf_threshold:
            detections.append({
                'bbox': bbox,
                'class_idx': pred_label,
                'confidence': confidence
            })
    
    print(f"æ£€æµ‹åˆ° {len(detections)} ä¸ªé«˜ç½®ä¿¡åº¦çª—å£")
    
    # æŒ‰ç±»åˆ«åˆ†åˆ«è¿›è¡ŒNMS
    final_results = []
    for class_idx in range(len(config['class_names'])):
        class_dets = [d for d in detections if d['class_idx'] == class_idx]
        if len(class_dets) == 0:
            continue
        
        boxes = [d['bbox'] for d in class_dets]
        scores = [d['confidence'] for d in class_dets]
        
        keep_indices = non_max_suppression(boxes, scores, iou_threshold=nms_threshold)
        
        for idx in keep_indices:
            final_results.append({
                'bbox': class_dets[idx]['bbox'],
                'predicted_class': config['class_names'][class_idx],
                'confidence': class_dets[idx]['confidence']
            })
    
    print(f"NMSåä¿ç•™ {len(final_results)} ä¸ªæ£€æµ‹æ¡†")
    
    # å¯è§†åŒ–
    vis_image = visualize_detections(image, final_results, show_true_labels=False)
    
    return vis_image, final_results


def visualize_detections(image: Image.Image, results: List[Dict], 
                         show_true_labels: bool = False) -> Image.Image:
    """å¯è§†åŒ–æ£€æµ‹ç»“æœ
    
    Args:
        image: PILå›¾åƒ
        results: æ£€æµ‹ç»“æœåˆ—è¡¨
        show_true_labels: æ˜¯å¦æ˜¾ç¤ºçœŸå®æ ‡ç­¾
        
    Returns:
        å¯è§†åŒ–åçš„å›¾åƒ
    """
    vis_image = image.copy()
    draw = ImageDraw.Draw(vis_image)
    
    # å°è¯•åŠ è½½å­—ä½“
    try:
        font = ImageFont.truetype("/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf", 16)
    except:
        font = ImageFont.load_default()
    
    for det in results:
        bbox = det['bbox']
        pred_class = det['predicted_class']
        confidence = det['confidence']
        
        # è·å–é¢œè‰²
        color = COLORS.get(pred_class, (255, 255, 255))
        
        # ç”»è¾¹ç•Œæ¡†
        draw.rectangle(bbox, outline=color, width=3)
        
        # å‡†å¤‡æ ‡ç­¾æ–‡æœ¬
        if show_true_labels and 'true_class' in det:
            true_class = det['true_class']
            correct = det['correct']
            status = "âœ“" if correct else "âœ—"
            label = f"{status} {pred_class} (GT: {true_class}) {confidence:.2f}"
        else:
            label = f"{pred_class} {confidence:.2f}"
        
        # ç”»æ ‡ç­¾èƒŒæ™¯
        text_bbox = draw.textbbox((bbox[0], bbox[1] - 20), label, font=font)
        draw.rectangle(text_bbox, fill=color)
        draw.text((bbox[0], bbox[1] - 20), label, fill=(255, 255, 255), font=font)
    
    return vis_image


def main():
    parser = argparse.ArgumentParser(description='è¡€ç»†èƒåˆ†ç±»æ¨ç† - DINOv3 + éšæœºæ£®æ—')
    
    # è¾“å…¥è¾“å‡º
    parser.add_argument('--image', type=str, required=True,
                       help='è¾“å…¥å›¾åƒè·¯å¾„')
    parser.add_argument('--xml', type=str, default=None,
                       help='XMLæ ‡æ³¨æ–‡ä»¶è·¯å¾„ï¼ˆå¦‚æœæä¾›ï¼Œåˆ™ä½¿ç”¨æ ‡æ³¨æ¡†è¿›è¡Œåˆ†ç±»ï¼›å¦åˆ™ä½¿ç”¨æ»‘åŠ¨çª—å£ï¼‰')
    parser.add_argument('--model_dir', type=str, default='output/bccd_rf_model',
                       help='æ¨¡å‹ç›®å½•')
    parser.add_argument('--output', type=str, default=None,
                       help='è¾“å‡ºå›¾åƒè·¯å¾„')
    
    # æ¨ç†å‚æ•°
    parser.add_argument('--conf_threshold', type=float, default=0.7,
                       help='ç½®ä¿¡åº¦é˜ˆå€¼ï¼ˆä»…ç”¨äºæ»‘åŠ¨çª—å£æ¨¡å¼ï¼‰')
    parser.add_argument('--nms_threshold', type=float, default=0.3,
                       help='NMSçš„IoUé˜ˆå€¼ï¼ˆä»…ç”¨äºæ»‘åŠ¨çª—å£æ¨¡å¼ï¼‰')
    parser.add_argument('--local_repo', type=str, default='/data/william/Workspace/dinov3',
                       help='æœ¬åœ°DINOv3ä»“åº“è·¯å¾„')
    parser.add_argument('--device', type=str, default='cuda',
                       help='è®¾å¤‡ (cuda æˆ– cpu)')
    
    args = parser.parse_args()
    
    # æ£€æŸ¥è®¾å¤‡
    if args.device == 'cuda' and not torch.cuda.is_available():
        print("è­¦å‘Š: CUDAä¸å¯ç”¨ï¼Œä½¿ç”¨CPU")
        args.device = 'cpu'
    
    print("="*80)
    print("è¡€ç»†èƒåˆ†ç±»æ¨ç† - DINOv3ç‰¹å¾ + éšæœºæ£®æ—åˆ†ç±»å™¨")
    print("="*80)
    
    # åŠ è½½é…ç½®å’Œæ¨¡å‹
    model_dir = Path(args.model_dir)
    config_path = model_dir / 'config.pkl'
    rf_path = model_dir / 'rf_classifier.pkl'
    
    print(f"ğŸ“¦ åŠ è½½é…ç½®: {config_path}")
    with open(config_path, 'rb') as f:
        config = pickle.load(f)
    
    print(f"ğŸ“¦ åŠ è½½éšæœºæ£®æ—æ¨¡å‹: {rf_path}")
    rf_classifier = joblib.load(rf_path)
    
    # åŠ è½½DINOv3æ¨¡å‹
    dinov3_model = load_dinov3_model(
        model_name=config['dinov3_model'],
        weights_path=config.get('dinov3_weights'),
        device=args.device,
        local_repo=args.local_repo
    )
    
    # ç¡®å®šæ¨ç†æ¨¡å¼
    image_path = Path(args.image)
    if not image_path.exists():
        print(f"é”™è¯¯: å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
        return
    
    if args.xml:
        # ä½¿ç”¨æ ‡æ³¨æ¡†è¿›è¡Œåˆ†ç±»
        xml_path = Path(args.xml)
        if not xml_path.exists():
            print(f"é”™è¯¯: XMLæ–‡ä»¶ä¸å­˜åœ¨: {xml_path}")
            return
        
        print(f"\næ¨¡å¼: ä½¿ç”¨æ ‡æ³¨æ¡†è¿›è¡Œåˆ†ç±»")
        print(f"å›¾åƒ: {image_path}")
        print(f"æ ‡æ³¨: {xml_path}")
        
        vis_image, results = classify_with_annotations(
            image_path, xml_path, dinov3_model, rf_classifier, 
            config, args.device
        )
        
        # ç»Ÿè®¡ç»“æœ
        total = len(results)
        correct = sum(1 for r in results if r['correct'])
        accuracy = correct / total if total > 0 else 0
        
        print(f"\nç»“æœç»Ÿè®¡:")
        print(f"  æ€»æ•°: {total}")
        print(f"  æ­£ç¡®: {correct}")
        print(f"  å‡†ç¡®ç‡: {accuracy:.2%}")
        
        # æŒ‰ç±»åˆ«ç»Ÿè®¡
        from collections import defaultdict
        class_stats = defaultdict(lambda: {'total': 0, 'correct': 0})
        for r in results:
            true_class = r['true_class']
            class_stats[true_class]['total'] += 1
            if r['correct']:
                class_stats[true_class]['correct'] += 1
        
        print(f"\nå„ç±»åˆ«å‡†ç¡®ç‡:")
        for class_name in config['class_names']:
            if class_name in class_stats:
                stats = class_stats[class_name]
                acc = stats['correct'] / stats['total'] if stats['total'] > 0 else 0
                print(f"  {class_name}: {stats['correct']}/{stats['total']} = {acc:.2%}")
        
    else:
        # ä½¿ç”¨æ»‘åŠ¨çª—å£è¿›è¡Œæ£€æµ‹
        print(f"\næ¨¡å¼: æ»‘åŠ¨çª—å£æ£€æµ‹")
        print(f"å›¾åƒ: {image_path}")
        print(f"ç½®ä¿¡åº¦é˜ˆå€¼: {args.conf_threshold}")
        print(f"NMSé˜ˆå€¼: {args.nms_threshold}")
        
        vis_image, results = detect_sliding_window(
            image_path, dinov3_model, rf_classifier, config,
            args.device, args.conf_threshold, args.nms_threshold
        )
        
        # ç»Ÿè®¡ç»“æœ
        from collections import Counter
        class_counts = Counter([r['predicted_class'] for r in results])
        
        print(f"\næ£€æµ‹ç»Ÿè®¡:")
        for class_name in config['class_names']:
            count = class_counts.get(class_name, 0)
            print(f"  {class_name}: {count}")
    
    # ä¿å­˜ç»“æœ
    if args.output:
        output_path = Path(args.output)
    else:
        output_dir = Path('output/bccd_rf_detections')
        output_dir.mkdir(parents=True, exist_ok=True)
        output_path = output_dir / f"{image_path.stem}_detection.png"
    
    vis_image.save(output_path)
    print(f"\nâœ“ ç»“æœä¿å­˜åˆ°: {output_path}")
    
    print("="*80)
    print("æ¨ç†å®Œæˆï¼")
    print("="*80)


if __name__ == '__main__':
    main()

